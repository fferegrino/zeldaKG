{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic infobox extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from slugify import slugify\n",
    "from glob import glob\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from urllib.parse import unquote\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Where are all those htmls?\n",
    "html_route = \"/Users/antonioferegrino/corpora/zelda-wikia2-clean/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    \"\"\"\n",
    "    Clean the url to met the structure adopted for the dataset\n",
    "    \"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    path = unquote(parsed.path)\n",
    "    if path.startswith(\"../\"):\n",
    "        path = path[3:]\n",
    "    path = path.replace(\"/\", \"%2F\")\n",
    "    query = None if parsed.query == '' else parsed.query\n",
    "    fragment = None if parsed.fragment == '' else parsed.fragment\n",
    "    return (path, query, fragment)\n",
    "\n",
    "parentheses = re.compile(\"\\(.+\\)\")\n",
    "\n",
    "def get_relation(label):\n",
    "    \"\"\"\n",
    "    Canonicalize the relationship\n",
    "    \"\"\"\n",
    "    lbl = re.sub(parentheses, '', label)\n",
    "    l =  slugify(lbl.strip(), separator='_')\n",
    "    return l.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoboxes = {}\n",
    "all_properties = set()\n",
    "\n",
    "for file in glob(html_route + \"*.html\"):\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    soup:BeautifulSoup = None\n",
    "    with open(file, \"r\", encoding=\"utf8\") as r:\n",
    "        soup = BeautifulSoup(r, \"lxml\")\n",
    "        \n",
    "    wikiaMainContent = soup.find('article', {'id':'WikiaMainContent'})\n",
    "    if not wikiaMainContent:\n",
    "        continue\n",
    "    \n",
    "    infobox = wikiaMainContent.find('aside', {'class':'portable-infobox'})\n",
    "    if not infobox:\n",
    "        continue\n",
    "    \n",
    "    infoboxes[filename] = {}\n",
    "    \n",
    "    items = infobox.findAll('div', {'class': 'pi-item'})\n",
    "    for item in items:\n",
    "        h3 = item.find('h3')\n",
    "        if not h3:\n",
    "            continue\n",
    "            \n",
    "        relation = get_relation(h3.text.strip())\n",
    "        all_properties.add(relation)\n",
    "        values = item.find('div', {'class':'pi-data-value'}, recursive=False)\n",
    "        \n",
    "        elements = [BeautifulSoup(s, \"html5lib\").body for s in ((''.join([str(element).strip() \n",
    "                              for element \n",
    "                              in values.contents \n",
    "                              if str(element).strip()])).split('<br/>'))]\n",
    "        links = []\n",
    "        for element in elements:\n",
    "            anchors = element.findAll('a')\n",
    "            for anchor in anchors:\n",
    "                path, query, fragment = clean_url(anchor['href'])\n",
    "                if not path.startswith(\"..%2\"):\n",
    "                    links.append(path)\n",
    "            \n",
    "        infoboxes[filename][relation] = links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"basic/infoboxes.json\", \"w\", encoding=\"utf8\") as w:\n",
    "    json.dump(infoboxes, w)\n",
    "with open(\"basic/all_properties.json\", \"w\", encoding=\"utf8\") as w:\n",
    "    json.dump(list(all_properties), w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform the data into something that can be loaded into neo4j \n",
    "\n",
    "via CSV files since I don't know how to import it from other sources **yet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities 7146\n",
      "Possible identified relationships 113\n"
     ]
    }
   ],
   "source": [
    "print(\"Entities %d\" % len(infoboxes))\n",
    "print(\"Possible identified relationships %d\" % len(all_properties))\n",
    "keys = list(infoboxes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veil Springs</td>\n",
       "      <td>Veil_Springs.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scorching Naginata</td>\n",
       "      <td>Scorching_Naginata.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rito Harp</td>\n",
       "      <td>Rito_Harp.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Strade</td>\n",
       "      <td>Strade.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rem's Shoe Shop</td>\n",
       "      <td>Rem's_Shoe_Shop.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                     page\n",
       "id                                             \n",
       "1         Veil Springs        Veil_Springs.html\n",
       "2   Scorching Naginata  Scorching_Naginata.html\n",
       "3            Rito Harp           Rito_Harp.html\n",
       "4               Strade              Strade.html\n",
       "5      Rem's Shoe Shop     Rem's_Shoe_Shop.html"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_page_title(file):\n",
    "    soup:BeautifulSoup = None\n",
    "    with open(file, \"r\", encoding=\"utf8\") as r:\n",
    "        soup = BeautifulSoup(r, \"lxml\")\n",
    "    wikiaMainContent = soup.find('article', {'id':'WikiaMainContent'})\n",
    "    title = wikiaMainContent.get('title',None)\n",
    "    if not wikiaMainContent or not title:\n",
    "        return None\n",
    "    return wikiaMainContent['title']\n",
    "        \n",
    "i = 1\n",
    "entities_lst = []\n",
    "reverse = {}\n",
    "for node in keys:\n",
    "    file = html_route + node\n",
    "    title = get_page_title(file)\n",
    "    if title is None:\n",
    "        print(infoboxes[node])\n",
    "        continue\n",
    "    \n",
    "    entities_lst.append([i, title, node])\n",
    "    reverse[node] = i\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "entities_df = pd.DataFrame(entities_lst, columns=['id','name','page']).set_index('id')\n",
    "entities_df.to_csv(\"basic/entities.csv\", encoding=\"utf8\")\n",
    "entities_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7146 entries, 1 to 7146\n",
      "Data columns (total 2 columns):\n",
      "name    7146 non-null object\n",
      "page    7146 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 167.5+ KB\n"
     ]
    }
   ],
   "source": [
    "entities_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>relationship</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FIRST_APPEARANCE</td>\n",
       "      <td>4476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COUNTRY</td>\n",
       "      <td>3068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>REGION</td>\n",
       "      <td>5784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT_OF_INTEREST</td>\n",
       "      <td>5095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT_OF_INTEREST</td>\n",
       "      <td>4441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   from       relationship    to\n",
       "0     1   FIRST_APPEARANCE  4476\n",
       "1     1            COUNTRY  3068\n",
       "2     1             REGION  5784\n",
       "3     1  POINT_OF_INTEREST  5095\n",
       "4     1  POINT_OF_INTEREST  4441"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(infoboxes.keys())\n",
    "relationships_lst = []\n",
    "for node in keys:\n",
    "    for relationship in infoboxes[node]:\n",
    "        for entity in infoboxes[node][relationship]:\n",
    "            id_ = reverse.get(entity, -1)\n",
    "            if id_ < 0: continue\n",
    "            else:\n",
    "                relationships_lst.append([reverse[node], relationship, id_])\n",
    "                \n",
    "relationships_df = pd.DataFrame(relationships_lst, columns=['from','relationship','to'])\n",
    "relationships_df.to_csv(\"basic/relationships.csv\", encoding=\"utf8\")\n",
    "relationships_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40664 entries, 0 to 40663\n",
      "Data columns (total 3 columns):\n",
      "from            40664 non-null int64\n",
      "relationship    40664 non-null object\n",
      "to              40664 non-null int64\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 953.1+ KB\n"
     ]
    }
   ],
   "source": [
    "relationships_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading into neo4j...\n",
    "\n",
    "```\n",
    "LOAD CSV WITH HEADERS FROM \"file:///entities.csv\"\n",
    "AS csvLine\n",
    "CREATE(e:Entity {id:toInteger(csvLine.id), name:csvLine.name, page: csvLine.page})\n",
    "```  \n",
    "\n",
    "Results in:  \n",
    "\n",
    "```\n",
    "Added 7146 labels, created 7146 nodes, set 21438 properties, completed after 902 ms.\n",
    "```\n",
    "\n",
    "Now, let's create an index:\n",
    "\n",
    "```\n",
    "CREATE INDEX ON :Entity(id)\n",
    "```\n",
    "\n",
    "Now, let's add the relationships:\n",
    "\n",
    "```\n",
    "LOAD CSV WITH HEADERS FROM \"file:///relationships.csv\"\n",
    "AS csvLine\n",
    "MATCH (f:Entity {id:toInteger(csvLine.from)}),(to:Entity{id:toInteger(csvLine.to)})\n",
    "CREATE (f)-[:RELATED {relation:csvLine.relationship}]->(to)\n",
    "```\n",
    "\n",
    "Results in:\n",
    "\n",
    "```\n",
    "Set 40664 properties, created 40664 relationships, completed after 2078 ms.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issuing simple queries\n",
    "\n",
    " > Who are the members of the Poe Sisters?\n",
    " \n",
    "```\n",
    "MATCH (e:Entity{name:'Poe Sisters'})-[r:RELATED{relation:'MEMBERS'}]->(e2:Entity)\n",
    "RETURN e,r,e2\n",
    "```\n",
    "\n",
    "<img src=\"images/poe_sisters.png\" />\n",
    "\n",
    "\n",
    " > Who are Dekus in TLOZ?\n",
    "\n",
    "```\n",
    "MATCH (e:Entity)-[r:RELATED{relation:'RACE'}]->(e2:Entity{name:'Deku'})\n",
    "RETURN e,r,e2\n",
    "```\n",
    "\n",
    "<img src=\"images/dekus.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
